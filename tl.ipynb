{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tl.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvE-dXKieWIq"
      },
      "source": [
        "# !pip install tensorflow-gpu"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G47Uz2w5nfu8",
        "outputId": "6042bf16-81f7-4b92-824a-463ff82637af"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Nov 28 02:13:32 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.38       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8     9W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyLxOy3eoHQn"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLntLHibolON"
      },
      "source": [
        "# import libraries\n",
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "from imutils import paths\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRI4dkaYoswY"
      },
      "source": [
        "# resize all the images\n",
        "IMAGE_SIZE = [224, 224]"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mc3D6iMmpRvc"
      },
      "source": [
        "train_path = '/content/drive/MyDrive/cdata/train' \n",
        "valid_path = '/content/drive/MyDrive/cdata/test'"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xfujqti6puxD"
      },
      "source": [
        "# Import the Resnet50 library as shown below and add preprocessing layer\n",
        "# Here we will be using imagenet weights\n",
        "\n",
        "vgg = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zYUQxo5p40S"
      },
      "source": [
        "# don't train existing wights\n",
        "for layer in vgg.layers:\n",
        "    layer.trainble = False"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsV2uYMyqBln",
        "outputId": "d11712b4-6a0d-4987-886b-a9b758422173"
      },
      "source": [
        "folder = glob('/content/drive/MyDrive/cdata/train/*')\n",
        "folder"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/cdata/train/Alice Englert_train',\n",
              " '/content/drive/MyDrive/cdata/train/Cynthia Nixon_train',\n",
              " '/content/drive/MyDrive/cdata/train/Finn Wittrock_train',\n",
              " '/content/drive/MyDrive/cdata/train/Jon Jon Briones_train',\n",
              " '/content/drive/MyDrive/cdata/train/Judy Davis_train',\n",
              " '/content/drive/MyDrive/cdata/train/Sarah Paulson_train']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3MvfpPrqShx"
      },
      "source": [
        "#Flatten because can able to add last number of layers\n",
        "x = Flatten()(vgg.output)"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EWT8YpgqnYz"
      },
      "source": [
        "prediction = Dense(len(folder),activation='softmax')(x)\n",
        "model = Model(inputs=vgg.input,outputs = prediction)# model object"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RY2upelkqs0s",
        "outputId": "8557d4c1-932e-4a5f-8a3b-3de291b5fcab"
      },
      "source": [
        "# view the summary\n",
        "model.summary()"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 6)                 150534    \n",
            "=================================================================\n",
            "Total params: 14,865,222\n",
            "Trainable params: 14,865,222\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erddiZ5OqwZ_"
      },
      "source": [
        "# tell the model what cost and optimization method to use\n",
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer='adam',\n",
        "  metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dppgLmGhrIuZ"
      },
      "source": [
        "# Use the Image Data Generator to import the images from the dataset\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMuxASworc7x",
        "outputId": "2e9db997-7f4e-4114-e501-c9b1096ad501"
      },
      "source": [
        "# Make sure you provide the same target size as initialied for the image size\n",
        "training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/cdata/train',\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical')"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 228 images belonging to 6 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nb6Sm6bPrshR",
        "outputId": "b4d057fd-6d64-4db3-8e04-4defb167f576"
      },
      "source": [
        "test_set = test_datagen.flow_from_directory('/content/drive/MyDrive/cdata/test',\n",
        "                                            target_size = (224, 224),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'categorical')"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 76 images belonging to 6 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nfLyyW8r7Jx",
        "outputId": "609abebb-2497-4f08-ef03-84c087909946"
      },
      "source": [
        "# fit the model\n",
        "# Run the cell. It will take some time to execute\n",
        "r = model.fit_generator(\n",
        "  training_set,\n",
        "  validation_data=test_set,\n",
        "  epochs=50,\n",
        "  steps_per_epoch=len(training_set),\n",
        "  validation_steps=len(test_set)\n",
        ")"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "2/8 [======>.......................] - ETA: 1s - loss: 0.8405 - accuracy: 0.6667WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0288s vs `on_train_batch_end` time: 0.0497s). Check your callbacks.\n",
            "8/8 [==============================] - 20s 2s/step - loss: 0.7310 - accuracy: 0.7149 - val_loss: 1.3760 - val_accuracy: 0.6316\n",
            "Epoch 2/50\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.6514 - accuracy: 0.7719 - val_loss: 1.3715 - val_accuracy: 0.6184\n",
            "Epoch 3/50\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.6103 - accuracy: 0.7500 - val_loss: 1.8457 - val_accuracy: 0.6053\n",
            "Epoch 4/50\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.5632 - accuracy: 0.7807 - val_loss: 1.5028 - val_accuracy: 0.6974\n",
            "Epoch 5/50\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.7101 - accuracy: 0.7325 - val_loss: 1.6928 - val_accuracy: 0.5789\n",
            "Epoch 6/50\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.9451 - accuracy: 0.6667 - val_loss: 1.5762 - val_accuracy: 0.6184\n",
            "Epoch 7/50\n",
            "8/8 [==============================] - 21s 3s/step - loss: 0.9498 - accuracy: 0.7018 - val_loss: 1.6098 - val_accuracy: 0.6842\n",
            "Epoch 8/50\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.7085 - accuracy: 0.6974 - val_loss: 1.5891 - val_accuracy: 0.6974\n",
            "Epoch 9/50\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.6226 - accuracy: 0.7807 - val_loss: 2.0851 - val_accuracy: 0.6316\n",
            "Epoch 10/50\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.5646 - accuracy: 0.8026 - val_loss: 1.7007 - val_accuracy: 0.6842\n",
            "Epoch 11/50\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.6147 - accuracy: 0.7763 - val_loss: 1.5529 - val_accuracy: 0.6711\n",
            "Epoch 12/50\n",
            "8/8 [==============================] - 20s 2s/step - loss: 0.5381 - accuracy: 0.7939 - val_loss: 2.0961 - val_accuracy: 0.6184\n",
            "Epoch 13/50\n",
            "8/8 [==============================] - 21s 3s/step - loss: 0.6445 - accuracy: 0.7763 - val_loss: 2.1526 - val_accuracy: 0.6316\n",
            "Epoch 14/50\n",
            "8/8 [==============================] - 21s 3s/step - loss: 0.7678 - accuracy: 0.7456 - val_loss: 1.8209 - val_accuracy: 0.6842\n",
            "Epoch 15/50\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.5594 - accuracy: 0.7939 - val_loss: 1.5907 - val_accuracy: 0.7105\n",
            "Epoch 16/50\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.5512 - accuracy: 0.7939 - val_loss: 1.9343 - val_accuracy: 0.6579\n",
            "Epoch 17/50\n",
            "8/8 [==============================] - 21s 3s/step - loss: 0.7138 - accuracy: 0.7588 - val_loss: 1.8306 - val_accuracy: 0.6842\n",
            "Epoch 18/50\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.5821 - accuracy: 0.7939 - val_loss: 2.0813 - val_accuracy: 0.5921\n",
            "Epoch 19/50\n",
            "8/8 [==============================] - 20s 2s/step - loss: 0.5416 - accuracy: 0.8026 - val_loss: 1.8287 - val_accuracy: 0.7500\n",
            "Epoch 20/50\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.4825 - accuracy: 0.8333 - val_loss: 1.9101 - val_accuracy: 0.7105\n",
            "Epoch 21/50\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.4313 - accuracy: 0.8640 - val_loss: 2.2037 - val_accuracy: 0.7237\n",
            "Epoch 22/50\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.4671 - accuracy: 0.8202 - val_loss: 3.4576 - val_accuracy: 0.5526\n",
            "Epoch 23/50\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.7804 - accuracy: 0.7193 - val_loss: 1.7144 - val_accuracy: 0.7105\n",
            "Epoch 24/50\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.4623 - accuracy: 0.8421 - val_loss: 2.1835 - val_accuracy: 0.6316\n",
            "Epoch 25/50\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.4454 - accuracy: 0.8377 - val_loss: 2.1524 - val_accuracy: 0.6711\n",
            "Epoch 26/50\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.4464 - accuracy: 0.8377 - val_loss: 2.0335 - val_accuracy: 0.7105\n",
            "Epoch 27/50\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.3784 - accuracy: 0.8728 - val_loss: 2.1890 - val_accuracy: 0.6974\n",
            "Epoch 28/50\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.2978 - accuracy: 0.8947 - val_loss: 2.3934 - val_accuracy: 0.6711\n",
            "Epoch 29/50\n",
            "8/8 [==============================] - 20s 2s/step - loss: 0.3003 - accuracy: 0.8904 - val_loss: 2.6498 - val_accuracy: 0.6842\n",
            "Epoch 30/50\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.3060 - accuracy: 0.8816 - val_loss: 2.2302 - val_accuracy: 0.6579\n",
            "Epoch 31/50\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.3496 - accuracy: 0.8772 - val_loss: 2.4937 - val_accuracy: 0.6842\n",
            "Epoch 32/50\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.2859 - accuracy: 0.8904 - val_loss: 3.2002 - val_accuracy: 0.7500\n",
            "Epoch 33/50\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.4263 - accuracy: 0.8640 - val_loss: 2.6435 - val_accuracy: 0.7105\n",
            "Epoch 34/50\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.2845 - accuracy: 0.8772 - val_loss: 2.9373 - val_accuracy: 0.6842\n",
            "Epoch 35/50\n",
            "8/8 [==============================] - 20s 2s/step - loss: 0.2345 - accuracy: 0.9079 - val_loss: 3.4339 - val_accuracy: 0.6447\n",
            "Epoch 36/50\n",
            "8/8 [==============================] - 20s 2s/step - loss: 0.3280 - accuracy: 0.9035 - val_loss: 3.7875 - val_accuracy: 0.6842\n",
            "Epoch 37/50\n",
            "8/8 [==============================] - 21s 3s/step - loss: 0.2829 - accuracy: 0.8816 - val_loss: 2.8895 - val_accuracy: 0.6711\n",
            "Epoch 38/50\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.2277 - accuracy: 0.9079 - val_loss: 3.0917 - val_accuracy: 0.6711\n",
            "Epoch 39/50\n",
            "8/8 [==============================] - 20s 2s/step - loss: 0.1809 - accuracy: 0.9430 - val_loss: 3.3811 - val_accuracy: 0.6842\n",
            "Epoch 40/50\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.1757 - accuracy: 0.9386 - val_loss: 4.0280 - val_accuracy: 0.6711\n",
            "Epoch 41/50\n",
            "8/8 [==============================] - 20s 2s/step - loss: 0.1371 - accuracy: 0.9561 - val_loss: 4.0084 - val_accuracy: 0.6447\n",
            "Epoch 42/50\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.1908 - accuracy: 0.9386 - val_loss: 4.1297 - val_accuracy: 0.6711\n",
            "Epoch 43/50\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.1851 - accuracy: 0.9518 - val_loss: 2.8528 - val_accuracy: 0.7237\n",
            "Epoch 44/50\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.9142 - accuracy: 0.7325 - val_loss: 2.4387 - val_accuracy: 0.6447\n",
            "Epoch 45/50\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.7565 - accuracy: 0.7325 - val_loss: 2.4008 - val_accuracy: 0.6974\n",
            "Epoch 46/50\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.6652 - accuracy: 0.7939 - val_loss: 2.5613 - val_accuracy: 0.6184\n",
            "Epoch 47/50\n",
            "8/8 [==============================] - 21s 3s/step - loss: 0.7355 - accuracy: 0.7632 - val_loss: 1.9716 - val_accuracy: 0.6711\n",
            "Epoch 48/50\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.5640 - accuracy: 0.7982 - val_loss: 2.2526 - val_accuracy: 0.6974\n",
            "Epoch 49/50\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.4501 - accuracy: 0.8377 - val_loss: 2.5700 - val_accuracy: 0.6711\n",
            "Epoch 50/50\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.3797 - accuracy: 0.8553 - val_loss: 2.3583 - val_accuracy: 0.7105\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpOfqRZTsFrj"
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model.save('vgg16_new_model.h5')"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdPbwB3RL3Vl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}